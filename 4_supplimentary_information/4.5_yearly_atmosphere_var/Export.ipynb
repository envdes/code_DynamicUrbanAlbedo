{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export atmosphere variables\n",
    "- This script is used to export atmosphere variables;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# surface\n",
    "sfile = '/mnt/iusers01/fatpou01/sees01/a16404ys/scratch/Projects/inputdata/lnd/clm2/surfdata_map/release-clm5.0.18/surfdata_0.9x1.25_hist_16pfts_Irrig_CMIP6_simyr1850_c190214.nc'\n",
    "# case1\n",
    "path = '/mnt/iusers01/fatpou01/sees01/a16404ys/scratch/Projects/archive/project1/case1/lnd_hist'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_0 = xr.open_dataset(sfile)\n",
    "mask = np.any(ds_0['PCT_URBAN'] != 0, axis=0)\n",
    "mask = mask.rename({'lsmlat': 'lat', 'lsmlon': 'lon'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_year = 2015\n",
    "end_year = 2100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "Arr_TBOT_1 = [] # atmospheric air temperature (K) (downscaled to columns in glacier regions)\n",
    "Arr_TBOT_1_JJA = [] # JJA: June, July, August\n",
    "Arr_TBOT_1_DJF = [] # DJF: December, January, February\n",
    "\n",
    "Arr_FSDS_1 = []\n",
    "Arr_FSDS_1_JJA = []\n",
    "Arr_FSDS_1_DJF = []\n",
    "\n",
    "Arr_FLDS_1 = []\n",
    "Arr_FLDS_1_JJA = []\n",
    "Arr_FLDS_1_DJF = []\n",
    "\n",
    "Arr_QBOT_1 = []\n",
    "Arr_QBOT_1_JJA = []\n",
    "Arr_QBOT_1_DJF = []\n",
    "\n",
    "Arr_PBOT_1 = []\n",
    "Arr_PBOT_1_JJA = []\n",
    "Arr_PBOT_1_DJF = []\n",
    "\n",
    "Arr_RAIN_1 = []\n",
    "Arr_RAIN_1_JJA = []\n",
    "Arr_RAIN_1_DJF = []\n",
    "\n",
    "Arr_SNOW_1 = []\n",
    "Arr_SNOW_1_JJA = []\n",
    "Arr_SNOW_1_DJF = []\n",
    "time = []\n",
    "\n",
    "for year in range(start_year,end_year):\n",
    "        fn = 'RCase1.clm2.h1.' + '%04.0f' % year + '-02-01-00000.nc'\n",
    "        year_1 = year+1\n",
    "        fn_1 = 'RCase1.clm2.h1.' + '%04.0f' % year_1 + '-02-01-00000.nc'\n",
    "        if(os.path.exists(path+fn)):\n",
    "            ds_1 = xr.open_dataset(path+fn)   # 打开第一个文件\n",
    "            ds_1_1 = xr.open_dataset(path+fn_1)\n",
    "            time.append(year)\n",
    "            TBOT_1 = ds_1['TBOT']- 273.15\n",
    "            TBOT_1_1 = ds_1_1['TBOT']- 273.15\n",
    "            FSDS_1 = ds_1['FSDS']\n",
    "            FSDS_1_1 = ds_1_1['FSDS']\n",
    "            FLDS_1 = ds_1['FLDS']\n",
    "            FLDS_1_1 = ds_1_1['FLDS']\n",
    "            QBOT_1 = ds_1['QBOT']\n",
    "            QBOT_1_1 = ds_1_1['QBOT']\n",
    "            PBOT_1 = ds_1['PBOT']\n",
    "            PBOT_1_1 = ds_1_1['PBOT']\n",
    "            RAIN_1 = ds_1['RAIN']\n",
    "            RAIN_1_1 = ds_1_1['RAIN']\n",
    "            SNOW_1 = ds_1['SNOW']\n",
    "            SNOW_1_1 = ds_1_1['SNOW']\n",
    "            \n",
    "            Arr_TBOT_1.append(TBOT_1.mean(dim='time').where(mask).mean().item())\n",
    "            Arr_TBOT_1_JJA.append(TBOT_1[6:9,:,:].mean(dim='time').where(mask).mean().item())\n",
    "            Arr_TBOT_1_DJF.append(xr.concat([TBOT_1.isel(time=11), TBOT_1_1.isel(time=slice(0, 2))], dim='time').mean(dim='time').where(mask).mean().item())\n",
    "\n",
    "            Arr_FSDS_1.append(FSDS_1.mean(dim='time').where(mask).mean().item())\n",
    "            Arr_FSDS_1_JJA.append(FSDS_1[6:9,:,:].mean(dim='time').where(mask).mean().item())\n",
    "            Arr_FSDS_1_DJF.append(xr.concat([FSDS_1.isel(time=11), FSDS_1_1.isel(time=slice(0, 2))], dim='time').mean(dim='time').where(mask).mean().item())\n",
    "            \n",
    "            Arr_FLDS_1.append(FLDS_1.mean(dim='time').where(mask).mean().item())\n",
    "            Arr_FLDS_1_JJA.append(FLDS_1[6:9,:,:].mean(dim='time').where(mask).mean().item())\n",
    "            Arr_FLDS_1_DJF.append(xr.concat([FLDS_1.isel(time=11), FLDS_1_1.isel(time=slice(0, 2))], dim='time').mean(dim='time').where(mask).mean().item())\n",
    "            \n",
    "            Arr_QBOT_1.append(QBOT_1.mean(dim='time').where(mask).mean().item())\n",
    "            Arr_QBOT_1_JJA.append(QBOT_1[6:9,:,:].mean(dim='time').where(mask).mean().item())\n",
    "            Arr_QBOT_1_DJF.append(xr.concat([QBOT_1.isel(time=11), QBOT_1_1.isel(time=slice(0, 2))], dim='time').mean(dim='time').where(mask).mean().item())\n",
    "            \n",
    "            Arr_PBOT_1.append(PBOT_1.mean(dim='time').where(mask).mean().item())\n",
    "            Arr_PBOT_1_JJA.append(PBOT_1[6:9,:,:].mean(dim='time').where(mask).mean().item())\n",
    "            Arr_PBOT_1_DJF.append(xr.concat([PBOT_1.isel(time=11), PBOT_1_1.isel(time=slice(0, 2))], dim='time').mean(dim='time').where(mask).mean().item())\n",
    "            \n",
    "            Arr_RAIN_1.append(RAIN_1.mean(dim='time').where(mask).mean().item())\n",
    "            Arr_RAIN_1_JJA.append(RAIN_1[6:9,:,:].mean(dim='time').where(mask).mean().item())\n",
    "            Arr_RAIN_1_DJF.append(xr.concat([RAIN_1.isel(time=11), RAIN_1_1.isel(time=slice(0, 2))], dim='time').mean(dim='time').where(mask).mean().item())\n",
    "            \n",
    "            Arr_SNOW_1.append(SNOW_1.mean(dim='time').where(mask).mean().item())\n",
    "            Arr_SNOW_1_JJA.append(SNOW_1[6:9,:,:].mean(dim='time').where(mask).mean().item())\n",
    "            Arr_SNOW_1_DJF.append(xr.concat([SNOW_1.isel(time=11), SNOW_1_1.isel(time=slice(0, 2))], dim='time').mean(dim='time').where(mask).mean().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict = {\n",
    "    'time' : time,\n",
    "    'Arr_TBOT_1' : Arr_TBOT_1,\n",
    "    'Arr_TBOT_1_JJA' : Arr_TBOT_1_JJA,\n",
    "    'Arr_TBOT_1_DJF' : Arr_TBOT_1_DJF,\n",
    "    'Arr_FSDS_1' : Arr_FSDS_1,\n",
    "    'Arr_FSDS_1_JJA' : Arr_FSDS_1_JJA,\n",
    "    'Arr_FSDS_1_DJF' : Arr_FSDS_1_DJF,\n",
    "    'Arr_FLDS_1' : Arr_FLDS_1,\n",
    "    'Arr_FLDS_1_JJA' : Arr_FLDS_1_JJA,\n",
    "    'Arr_FLDS_1_DJF' : Arr_FLDS_1_DJF,\n",
    "    'Arr_QBOT_1' : Arr_QBOT_1,\n",
    "    'Arr_QBOT_1_JJA' : Arr_QBOT_1_JJA,\n",
    "    'Arr_QBOT_1_DJF' : Arr_QBOT_1_DJF,\n",
    "    'Arr_PBOT_1' : Arr_PBOT_1,\n",
    "    'Arr_PBOT_1_JJA' : Arr_PBOT_1_JJA,\n",
    "    'Arr_PBOT_1_DJF' : Arr_PBOT_1_DJF,\n",
    "    'Arr_RAIN_1' : Arr_RAIN_1,\n",
    "    'Arr_RAIN_1_JJA' : Arr_RAIN_1_JJA,\n",
    "    'Arr_RAIN_1_DJF' : Arr_RAIN_1_DJF,\n",
    "    'Arr_SNOW_1' : Arr_SNOW_1,\n",
    "    'Arr_SNOW_1_JJA' : Arr_SNOW_1_JJA,\n",
    "    'Arr_SNOW_1_DJF' : Arr_SNOW_1_DJF\n",
    "}\n",
    "pd.DataFrame(data_dict).to_csv('atm.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
