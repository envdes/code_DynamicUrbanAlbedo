{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export UHI data\n",
    "- This script is used to export UHI mean data;\n",
    "- Simulations: CNTL, ROOF_0.9, ROOF_TV;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "home_path = '/work/n02/n02/yuansun/'\n",
    "# surface\n",
    "sfile = home_path + 'cesm/cesm_inputdata/lnd/clm2/surfdata_map/release-clm5.0.18/surfdata_0.9x1.25_hist_16pfts_Irrig_CMIP6_simyr1850_c190214.nc'\n",
    "#case0: CNTL\n",
    "path_0 = home_path + 'cesm/archive/case0/lnd/hist/'\n",
    "#case1: ROOF_0.9\n",
    "path_1 = home_path + 'cesm/archive/case1/lnd/hist/'\n",
    "#case2: ROOF_DA\n",
    "path_2 = home_path + 'cesm/archive/case2/lnd/hist/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_year = 2015\n",
    "end_year = 2100\n",
    "ds_0 = xr.open_dataset(sfile)\n",
    "mask = np.any(ds_0['PCT_URBAN'] != 0, axis=0)\n",
    "mask = mask.rename({'lsmlat': 'lat', 'lsmlon': 'lon'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# case0 UHI\n",
    "Arr_CUHI_0 = []\n",
    "Arr_CUHI_0_JJA = []\n",
    "Arr_CUHI_0_DJF = []\n",
    "Arr_SUHI_0 = []\n",
    "Arr_SUHI_0_JJA = []\n",
    "Arr_SUHI_0_DJF = []\n",
    "time = []\n",
    "for year in range(start_year,end_year):\n",
    "        fn = 'case0.clm2.h1.' + '%04.0f' % year + '-02-01-00000.nc'\n",
    "        year_1 = year + 1\n",
    "        fn_1 = 'case0.clm2.h1.' + '%04.0f' % year_1 + '-02-01-00000.nc'\n",
    "        if(os.path.exists(path_0+fn)):\n",
    "            time.append(year)\n",
    "            ds = xr.open_dataset(path_0+fn)\n",
    "            ds_1 = xr.open_dataset(path_0+fn_1)\n",
    "            cuhi = (ds['TSA_U']- ds['TSA_R']).where(mask)\n",
    "            cuhi_1 = (ds_1['TSA_U']- ds_1['TSA_R']).where(mask)\n",
    "            suhi = (ds['TG_U']- ds['TG_R']).where(mask)\n",
    "            suhi_1 = (ds_1['TG_U']- ds_1['TG_R']).where(mask)\n",
    "            Arr_CUHI_0.append(cuhi.mean().item())\n",
    "            Arr_CUHI_0_JJA.append(cuhi[6:9,:,:].mean().item())\n",
    "            Arr_CUHI_0_DJF.append(xr.concat([cuhi.isel(time=11), cuhi_1.isel(time=slice(0, 2))], dim='time').mean().item())\n",
    "            Arr_SUHI_0.append(suhi.mean().item())\n",
    "            Arr_SUHI_0_JJA.append(suhi[6:9,:,:].mean().item())\n",
    "            Arr_SUHI_0_DJF.append(xr.concat([suhi.isel(time=11), suhi_1.isel(time=slice(0, 2))], dim='time').mean().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict0 = {\n",
    "    'time': time,\n",
    "    'Arr_CUHI_0': Arr_CUHI_0,\n",
    "    'Arr_CUHI_0_JJA': Arr_CUHI_0_JJA,\n",
    "    'Arr_CUHI_0_DJF': Arr_CUHI_0_DJF,\n",
    "    'Arr_SUHI_0': Arr_SUHI_0,\n",
    "    'Arr_SUHI_0_JJA': Arr_SUHI_0_JJA,\n",
    "    'Arr_SUHI_0_DJF': Arr_SUHI_0_DJF}\n",
    "df0 = pd.DataFrame(data_dict0)\n",
    "df0.to_csv('exported_data_UHI0.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# case1 UHI\n",
    "Arr_CUHI_1 = []\n",
    "Arr_CUHI_1_JJA = []\n",
    "Arr_CUHI_1_DJF = []\n",
    "Arr_SUHI_1 = []\n",
    "Arr_SUHI_1_JJA = []\n",
    "Arr_SUHI_1_DJF = []\n",
    "\n",
    "for year in range(start_year,end_year):\n",
    "        fn = 'case1.clm2.h1.' + '%04.0f' % year + '-02-01-00000.nc'\n",
    "        year_1 = year + 1\n",
    "        fn_1 = 'case1.clm2.h1.' + '%04.0f' % year_1 + '-02-01-00000.nc'\n",
    "        if(os.path.exists(path_1+fn)):\n",
    "            ds = xr.open_dataset(path_1+fn)\n",
    "            ds_1 = xr.open_dataset(path_1+fn_1)\n",
    "            cuhi = (ds['TSA_U']- ds['TSA_R']).where(mask)\n",
    "            cuhi_1 = (ds_1['TSA_U']- ds_1['TSA_R']).where(mask)\n",
    "            suhi = (ds['TG_U']- ds['TG_R']).where(mask)\n",
    "            suhi_1 = (ds_1['TG_U']- ds_1['TG_R']).where(mask)\n",
    "            Arr_CUHI_1.append(cuhi.mean().item())\n",
    "            Arr_CUHI_1_JJA.append(cuhi[6:9,:,:].mean().item())\n",
    "            Arr_CUHI_1_DJF.append(xr.concat([cuhi.isel(time=11), cuhi_1.isel(time=slice(0, 2))], dim='time').mean().item())\n",
    "            Arr_SUHI_1.append(suhi.mean().item())\n",
    "            Arr_SUHI_1_JJA.append(suhi[6:9,:,:].mean().item())\n",
    "            Arr_SUHI_1_DJF.append(xr.concat([suhi.isel(time=11), suhi_1.isel(time=slice(0, 2))], dim='time').mean().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict1 = {\n",
    "    'Arr_CUHI_1': Arr_CUHI_1,\n",
    "    'Arr_CUHI_1_JJA': Arr_CUHI_1_JJA,\n",
    "    'Arr_CUHI_1_DJF': Arr_CUHI_1_DJF,\n",
    "    'Arr_SUHI_1': Arr_SUHI_1,\n",
    "    'Arr_SUHI_1_JJA': Arr_SUHI_1_JJA,\n",
    "    'Arr_SUHI_1_DJF': Arr_SUHI_1_DJF}\n",
    "df1 = pd.DataFrame(data_dict1)\n",
    "df1.to_csv('exported_data_UHI1.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# case2 UHI\n",
    "Arr_CUHI_2 = []\n",
    "Arr_CUHI_2_JJA = []\n",
    "Arr_CUHI_2_DJF = []\n",
    "Arr_SUHI_2 = []\n",
    "Arr_SUHI_2_JJA = []\n",
    "Arr_SUHI_2_DJF = []\n",
    "\n",
    "for year in range(start_year,end_year):\n",
    "        fn = 'case2.clm2.h1.' + '%04.0f' % year + '-02-01-00000.nc'\n",
    "        year_1 = year + 1\n",
    "        fn_1 = 'case2.clm2.h1.' + '%04.0f' % year_1 + '-02-01-00000.nc'\n",
    "        if(os.path.exists(path_2+fn)):\n",
    "            ds = xr.open_dataset(path_2+fn)\n",
    "            ds_1 = xr.open_dataset(path_2+fn_1)\n",
    "            cuhi = (ds['TSA_U']- ds['TSA_R']).where(mask)\n",
    "            cuhi_1 = (ds_1['TSA_U']- ds_1['TSA_R']).where(mask)\n",
    "            suhi = (ds['TG_U']- ds['TG_R']).where(mask)\n",
    "            suhi_1 = (ds_1['TG_U']- ds_1['TG_R']).where(mask)\n",
    "            Arr_CUHI_2.append(cuhi.mean().item())\n",
    "            Arr_CUHI_2_JJA.append(cuhi[6:9,:,:].mean().item())\n",
    "            Arr_CUHI_2_DJF.append(xr.concat([cuhi.isel(time=11), cuhi_1.isel(time=slice(0, 2))], dim='time').mean().item())\n",
    "            Arr_SUHI_2.append(suhi.mean().item())\n",
    "            Arr_SUHI_2_JJA.append(suhi[6:9,:,:].mean().item())\n",
    "            Arr_SUHI_2_DJF.append(xr.concat([suhi.isel(time=11), suhi_1.isel(time=slice(0, 2))], dim='time').mean().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict2 = {\n",
    "    'Arr_CUHI_2': Arr_CUHI_2,\n",
    "    'Arr_CUHI_2_JJA': Arr_CUHI_2_JJA,\n",
    "    'Arr_CUHI_2_DJF': Arr_CUHI_2_DJF,\n",
    "    'Arr_SUHI_2': Arr_SUHI_2,\n",
    "    'Arr_SUHI_2_JJA': Arr_SUHI_2_JJA,\n",
    "    'Arr_SUHI_2_DJF': Arr_SUHI_2_DJF,\n",
    "}\n",
    "\n",
    "df2 = pd.DataFrame(data_dict2)\n",
    "df2.to_csv('exported_data_UHI2.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
